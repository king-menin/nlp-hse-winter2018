{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "sem1.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [
        "A2GlHrdvwNrS",
        "ehIHYotlwUPG",
        "3eNYvNQbvvYJ",
        "XIbhjOCivvYR",
        "cBqltsx5vvY2",
        "-_3tbIdivvY8",
        "fRHiJz0ZvvZp",
        "c-A0O3VSvvZw",
        "DgSCJTaWvvaG",
        "laHZHIwSvvay",
        "YgDAG726vvbA",
        "ccToX2lFvvbD",
        "G6fyAUHDvvbd",
        "zeXRcpaSvvbl",
        "2Wi1Ux1Ivvbw",
        "-r3DUfLdvvb3",
        "N_TnTp4jvvb-"
      ]
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    }
  },
  "cells": [
    {
      "metadata": {
        "id": "2zyp68invvYA",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#### Необходимые библиотеки для занятия    \n",
        "Обычно <b>ставятся автоматически</b> при установке jupyter notebook:\n",
        "<ul>\n",
        "<li><i>numpy</i> - для работы с массивами\n",
        "\n",
        "```!pip3 install numpy```\n",
        "</li>\n",
        "<li><i>sklearn</i> - блиблиотека для работы с данными, содержит большинство алгоритмов машинного обучения</li>\n",
        "\n",
        "```!pip3 install sklearn```\n",
        "\n",
        "</li>\n",
        "<li><i>pandas</i> - библиотека для удобной работы с данными как с DataFrame\n",
        "\n",
        "```!pip3 install pandas```\n",
        "</li>\n",
        "<li><i>matplotlib</i> - библиотека для визуализации\n",
        "\n",
        "```!pip3 install matplotlib```\n",
        "</li>\n",
        "</ul>\n",
        "\n",
        "Обычно <b>не ставятся автоматически</b> при установке jupyter notebook:\n",
        "<ul>\n",
        "<li><i>rusenttokenize</i> - для разбиения текста на предложения (русский язык)\n",
        "\n",
        "```!pip3 install rusenttokenize```\n",
        "</li>\n",
        "<li><i>nltk</i> - фреймворк для обработки ЕЯ\n",
        "\n",
        "```!pip3 install nltk```\n",
        "\n",
        "Также необходимо выполнить следующие команды, чтобы загрузить данные:\n",
        "\n",
        "\n",
        "```import nltk```\n",
        "\n",
        "```nltk.download('treebank')```\n",
        "\n",
        "```nltk.download('stopwords')```\n",
        "\n",
        "```nltk.download('punkt')```\n",
        "\n",
        "<li><i>python-crfsuite</i> - для использования CRF</li>\n",
        "\n",
        "```!pip3 install python-crfsuite```\n",
        "</li>\n",
        "<li><i>pymorphy2</i> - морфологический анализатор русского языка\n",
        "\n",
        "```!pip3 install pymorphy2```\n",
        "</li>\n",
        "</ul>"
      ]
    },
    {
      "metadata": {
        "id": "A2GlHrdvwNrS",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### For colab:\n",
        "Install libs"
      ]
    },
    {
      "metadata": {
        "id": "h74PumtUvzFh",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!pip3 install nltk\n",
        "import nltk\n",
        "nltk.download('treebank')\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "8NKHOx0fwEPG",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!pip3 install python-crfsuite\n",
        "!pip3 install pymorphy2"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "2KgvFYEIwzue",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!pip3 install rusenttokenize"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ehIHYotlwUPG",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Load data"
      ]
    },
    {
      "metadata": {
        "id": "2TXQkgW1wKK2",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!wget -O negative.txt https://raw.githubusercontent.com/king-menin/nlp-hse-winter2018/master/lecture%201.%20intro%20to%20nlp/negative.txt\n",
        "!wget -O positive.txt https://raw.githubusercontent.com/king-menin/nlp-hse-winter2018/master/lecture%201.%20intro%20to%20nlp/positive.txt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "5aaFklgSwi1j",
        "colab_type": "code",
        "outputId": "6af07cbe-5a5c-459e-b2e0-6b314a2f6413",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "!ls"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "negative.txt  positive.txt  sample_data\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "ts34aCHbvvYC",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Часть 1. Предобработка текста и классификация"
      ]
    },
    {
      "metadata": {
        "id": "PkWsuQYuvvYE",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "\n",
        "import numpy as np\n",
        "np.random.seed(1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "3eNYvNQbvvYJ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## 1.1 Прочитайте текст в файлах positive.txt и negative.txt"
      ]
    },
    {
      "metadata": {
        "id": "ciP1LQ05vvYK",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "with open(\"positive.txt\", \"r\", encoding=\"utf-8\") as file:\n",
        "    positive_plain = <your code here>\n",
        "\n",
        "with open(\"negative.txt\", \"r\", encoding=\"utf-8\") as file:\n",
        "    negative_plain = <your code here>"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "VC9hBIg6vvYO",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "print(positive_plain[:400], negative_plain[:400], sep=\"\\n\\n\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "XIbhjOCivvYR",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## 1.2. Разбейте данные на предложения\n",
        "\n",
        "Для токенизации используйте nltk.sent_tokenize. чтобы удалить имен пользователей из сообщений напишите регулярное выражение.\n",
        "\n",
        "<b>Классы символов в регулярных выражениях</b>:\n",
        "\n",
        "[A-Z] – символы верхнего регистра (латиница)\n",
        "\n",
        "[a-z] – символы нижнего регистра (латиница)\n",
        "\n",
        "[А-Я] – символы верхнего регистра (кириллица)\n",
        "\n",
        "[а-я] – символы нижнего регистра (кириллица)\n",
        "\n",
        "[0-9] или \\d – цифра\n",
        "\n",
        "[^0-9] или \\D – любой символ, кроме цифры\n",
        "\n",
        ". – Один любой символ, кроме новой строки \\n.\n",
        "\n",
        "? – 0 или 1 вхождение шаблона слева\n",
        "\n",
        "\\+ – 1 и более вхождений шаблона слева\n",
        "\n",
        "\\* – 0 и более вхождений шаблона слева\n",
        "\n",
        "\\w – Любая цифра или буква (\\W — все, кроме буквы или цифры)\n",
        "\n",
        "\\d – Любая цифра [0-9] (\\D — все, кроме цифры)\n",
        "\n",
        "\\s – Любой пробельный символ (\\S — любой непробельнй символ)\n",
        "\n",
        "\\b – Граница слова\n",
        "\n",
        "[..] – дин из символов в скобках ([^..] — любой символ, кроме тех, что в скобках)\n",
        "\n",
        "\\ – Экранирование специальных символов (\\. означает точку или \\+ — знак «плюс»)\n",
        "\n",
        "^ и $ – Начало и конец строки соответственно\n",
        "\n",
        "{n,m} – От n до m вхождений ({,m} — от 0 до m)\n",
        "\n",
        "a|b – Соответствует a или b\n",
        "\n",
        "() – Группирует выражение и возвращает найденный текст\n",
        "\n",
        "\\t, \\n, \\r – Символ табуляции, новой строки и возврата каретки соответственно"
      ]
    },
    {
      "metadata": {
        "id": "dJuvsWrzvvYS",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import re\n",
        "# from nltk import sent_tokenize\n",
        "from rusenttokenize import ru_sent_tokenize\n",
        "\n",
        "\n",
        "def split_data(text):\n",
        "    # Избавляемся от имен пользователей, указанных в письмах\n",
        "    name = <your code here>\n",
        "    res = name.sub(\"\", text)\n",
        "    # Удалите лишние переносы строк и разбейте на предложения по знаку \".\"\n",
        "    # res = sent_tokenize(res.replace(\"\\n\", \"\"))\n",
        "    res = ru_sent_tokenize(res.replace(\"\\n\", \"\"))\n",
        "    return res"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "qtNrkhZSvvYW",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "positive = split_data(positive_plain)\n",
        "negative = split_data(negative_plain)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "zsOC1wi_vvYZ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "len(positive), len(negative)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "JsNlbeq-vvYe",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "pos_labels = [1] * len(positive)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "eCMs3KvKvvYl",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "neg_labels = [0] * len(negative)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "7WzQG5S5vvYr",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Объединим все в один список"
      ]
    },
    {
      "metadata": {
        "id": "29yy5BcNvvYt",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "all_text = positive + negative\n",
        "all_labels = pos_labels + neg_labels"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "9TJKxGV2vvYy",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "len(all_text)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "cBqltsx5vvY2",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## 1.3. Удалите пустые строки, если они есть"
      ]
    },
    {
      "metadata": {
        "id": "EbUeXBBDvvY4",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "all_text_ = []\n",
        "all_labels_ = []\n",
        "\n",
        "<your code here>\n",
        "\n",
        "all_text = all_text_\n",
        "all_labels = all_labels_"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "-_3tbIdivvY8",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## 1. 4. Предварительный анализ коллекции"
      ]
    },
    {
      "metadata": {
        "id": "mlS8hTPqvvY9",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#### Средняя длина предложений"
      ]
    },
    {
      "metadata": {
        "id": "JtEAowcevvY-",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import pandas as pd"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "m3i_Wpk-vvZB",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "df = pd.DataFrame(all_text)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "C_Z2QBHxvvZF",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "len_data = df[0].apply(len)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "43u7a996vvZL",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "len_data.describe()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "-8rZeQZGvvZR",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#### Длины текстов в символах"
      ]
    },
    {
      "metadata": {
        "id": "6auEQwoDvvZT",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "%pylab inline"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ZYVrcdEdvvZW",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "fig, ax = plt.subplots()\n",
        "\n",
        "n, bins, patches = ax.hist(len_data.tolist())\n",
        "\n",
        "fig.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "VvSdL8aUvvZZ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#### Самые частые слова"
      ]
    },
    {
      "metadata": {
        "id": "FgphvxdPvvZZ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Токенизируйте предложения на слова (nltk.word_tokenize)"
      ]
    },
    {
      "metadata": {
        "id": "AgyHHrIfvvZa",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from nltk import word_tokenize\n",
        "\n",
        "\n",
        "all_text = [word_tokenize(line) for line in all_text]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "xn_zXzuPvvZe",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from nltk import FreqDist\n",
        "\n",
        "\n",
        "n_types = []\n",
        "n_tokens = []\n",
        "fd = FreqDist()\n",
        "for line in all_text:\n",
        "    fd.update(line)\n",
        "    n_types.append(len(fd))\n",
        "    n_tokens.append(sum(list(fd.values())))\n",
        "for i in fd.most_common(10):\n",
        "    print(i)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "TtUzN568vvZh",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#### Закон Ципфа\n",
        "\n",
        "В любом достаточно большом тексте ранг типа обратно пропорционален его частоте: f=a/r\n",
        "\n",
        "f – частота типа, r – ранг типа, a – параметр, для славянских языков – около 0.07"
      ]
    },
    {
      "metadata": {
        "id": "I8Y-ICsDvvZi",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "freqs = list(fd.values())\n",
        "freqs = sorted(freqs, reverse = True)\n",
        "\n",
        "fig, ax = plt.subplots()\n",
        "ax.plot(freqs[:300], range(300))\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Md-yj35CvvZl",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#### Закон Хипса\n",
        "\n",
        "С увеличением длины текста (количества токенов), количество типов увеличивается в соответствии с законом: |V|=K∗N^b\n",
        "\n",
        "N – число токенов, |V| – количество типов в словаре, K,b – параметры, обычно K∈[10,100],b∈[0.4,0.6]"
      ]
    },
    {
      "metadata": {
        "id": "NJ3vnrl9vvZm",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "fig, ax = plt.subplots()\n",
        "ax.plot(n_types, n_tokens)\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "fRHiJz0ZvvZp",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## 1.5. Подготовим данные для nltk.NaiveBayesClassifier\n",
        "\n",
        "Классификатор принимает данные о предложении в виде словаря {\"слово\": #количество встреч в предожении}\n",
        "\n",
        "Используйсте Counter. Пример работы:\n",
        "\n",
        "`Counter('abracadabra')`\n",
        "\n",
        ">Counter({'a': 5, 'b': 2, 'c': 1, 'd': 1, 'r': 2})"
      ]
    },
    {
      "metadata": {
        "id": "8KvwGb86vvZq",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from collections import Counter"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "vq4w7qLnvvZu",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "all_text = <your code here>"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "c-A0O3VSvvZw",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## 1.6. Обучим модель"
      ]
    },
    {
      "metadata": {
        "id": "TnUuD70SvvZx",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "from nltk import NaiveBayesClassifier\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "pKhbG5ntvvZ2",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "train_indecies, test_indecies = train_test_split(np.arange(len(all_text)), test_size=0.3, random_state=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Wljy2QcNvvZ7",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "all_text = np.array(all_text)\n",
        "all_labels = np.array(all_labels)\n",
        "\n",
        "X_train, X_test = all_text[train_indecies], all_text[test_indecies]\n",
        "y_train, y_test = all_labels[train_indecies], all_labels[test_indecies]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "IlsV8jltvvZ-",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "clf = NaiveBayesClassifier.train(zip(X_train, y_train))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "_J6R5jzkvvaC",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Протестируем качество классификации"
      ]
    },
    {
      "metadata": {
        "id": "HyepqQpOvvaD",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "pred = clf.classify_many(X_test)\n",
        "accuracy_score(y_test, pred)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "DgSCJTaWvvaG",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## 1.7. Добавим признаков\n",
        "\n",
        "Для каждого примера добавим количество частей речи в нем. Если мы встретили знак пунктуации, то обозначим его как 'PNCT'."
      ]
    },
    {
      "metadata": {
        "id": "yAm6akUXvvaH",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import pymorphy2"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "PD6COBuFvvaJ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "morph = pymorphy2.analyzer.MorphAnalyzer()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "p5qgTgwLvvaM",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Используйте pymorphy2.analyzer.MorphAnalyzer.parse"
      ]
    },
    {
      "metadata": {
        "id": "LIoFq5sHvvaN",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "all_text_with_pos = []\n",
        "for sample in all_text:\n",
        "    update = Counter(sample)\n",
        "    for word, count in sample.items():\n",
        "        <your code here>\n",
        "    all_text_with_pos.append(update)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "m8sm-_0LvvaR",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "all_text_with_pos = np.array(all_text_with_pos)\n",
        "all_labels = np.array(all_labels)\n",
        "\n",
        "X_train, X_test = all_text_with_pos[train_indecies], all_text_with_pos[test_indecies]\n",
        "y_train, y_test = all_labels[train_indecies], all_labels[test_indecies]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "91QLaDP5vvaa",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "clf = NaiveBayesClassifier.train(zip(X_train, y_train))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "q_ML96Dlvvae",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "pred = clf.classify_many(X_test)\n",
        "accuracy_score(y_test, pred)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "1M_XNR_Uvvai",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Попробуем лемматизировать слова\n",
        "\n",
        "Обучите тот же классификатор но на примерах, где все слова в нормальной форме."
      ]
    },
    {
      "metadata": {
        "id": "D__e3BVMvval",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "all_text_with_pos = []\n",
        "for sample in all_text:\n",
        "    update = Counter()\n",
        "    for word, count in sample.items():\n",
        "        <your code here>\n",
        "    all_text_with_pos.append(update)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "FbtMzYw3vvas",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "all_text_with_pos = np.array(all_text_with_pos)\n",
        "all_labels = np.array(all_labels)\n",
        "\n",
        "X_train, X_test = all_text_with_pos[train_indecies], all_text_with_pos[test_indecies]\n",
        "y_train, y_test = all_labels[train_indecies], all_labels[test_indecies]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "9NN2ozbNvvaw",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "clf = NaiveBayesClassifier.train(zip(X_train, y_train))\n",
        "\n",
        "pred = clf.classify_many(X_test)\n",
        "accuracy_score(y_test, pred)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "laHZHIwSvvay",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Удалим стоп-слова"
      ]
    },
    {
      "metadata": {
        "collapsed": true,
        "id": "093KonqIvvay",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from nltk.corpus import stopwords\n",
        "\n",
        "stops = stopwords.words(\"russian\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "collapsed": true,
        "id": "sT9mEW9Bvva2",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "all_text_without_stops = []\n",
        "for sample in all_text:\n",
        "    update = Counter()\n",
        "    for word, count in sample.items():\n",
        "        <your code here>\n",
        "    all_text_without_stops.append(update)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "collapsed": true,
        "id": "biC3D2F6vva3",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "all_text_without_stops = np.array(all_text_without_stops)\n",
        "all_labels = np.array(all_labels)\n",
        "\n",
        "X_train, X_test = all_text_without_stops[train_indecies], all_text_without_stops[test_indecies]\n",
        "y_train, y_test = all_labels[train_indecies], all_labels[test_indecies]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "collapsed": true,
        "id": "3gbJ-n0avva8",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "clf = NaiveBayesClassifier.train(zip(X_train, y_train))\n",
        "\n",
        "pred = clf.classify_many(X_test)\n",
        "accuracy_score(y_test, pred)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "YgDAG726vvbA",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Как менялось качество? Почему?"
      ]
    },
    {
      "metadata": {
        "collapsed": true,
        "id": "SOX6TuoRvvbB",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "<your answer here>"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ccToX2lFvvbD",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Часть 2. Использование знаний морфологии для генерации текста\n",
        "\n",
        "Задание: написать шаблон вида: {person} {action} {count} {target}. Где\n",
        "\n",
        "Person - лицо которое выполняет действие action. Каждое такое действие может быть в трех временах (настоящее, прошедшее и будущее). Действие выполняется с целью target. Такая цель - это некоторый объект или объекты числом count. count>0.\n",
        "\n",
        "Используйте make_agree_with_number, parse и inflect из библиотеки pymorphy2.\n",
        "\n",
        "Времена глаголов в документации pymorphy2: past (прошедшее), pres (настоящее), futr (будущее)."
      ]
    },
    {
      "metadata": {
        "id": "Nihun42HvvbG",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import pymorphy2\n",
        "morph = pymorphy2.analyzer.MorphAnalyzer()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "uxIwtPVfvvbJ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Согласование существительного с числом."
      ]
    },
    {
      "metadata": {
        "id": "W9riKoiZvvbK",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "butyavka = morph.parse(\"бутявка\")[0]\n",
        "butyavka.make_agree_with_number(2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "0WNQ7rSmvvbQ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Чтобы поставить слово в нужную форму используется inflect"
      ]
    },
    {
      "metadata": {
        "id": "z7q4PIzOvvbQ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "butyavka.inflect({'gent'})  # нет кого? (родительный падеж)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "jPzshACSvvbT",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "butyavka.inflect({'plur', 'gent'})"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "xzbq8YTkvvbW",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def genarate(person, action, time, count, target):\n",
        "    # Поставьте action в нужное время\n",
        "    action = <your code here>\n",
        "    # Согласуйте target с числом\n",
        "    target = <your code here>\n",
        "    return <your code here>"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "yRoHaFgvvvbY",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "genarate(\"Антон\", \"купить\", \"past\", 5, \"товар\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "5KHXQoiFvvbb",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Часть 3. Статистические морфологические анализаторы"
      ]
    },
    {
      "metadata": {
        "id": "G6fyAUHDvvbd",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## 3.1. Загрузим данные из nltk.treebank"
      ]
    },
    {
      "metadata": {
        "collapsed": true,
        "id": "GvFholLTvvbf",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from nltk.corpus import treebank"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "collapsed": true,
        "id": "M5fWCn6vvvbh",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "sentences = treebank.tagged_sents()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "zeXRcpaSvvbl",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## 3.2. Выделим признаки"
      ]
    },
    {
      "metadata": {
        "collapsed": true,
        "id": "mftl9NY9vvbm",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def features(sentence, index):\n",
        "    return {\n",
        "        'word': sentence[index],\n",
        "        'is_first': index == 0,\n",
        "        'is_last': index == len(sentence) - 1,\n",
        "        'prefix-1': sentence[index][0],\n",
        "        'prefix-2': sentence[index][:2],\n",
        "        'prefix-3': sentence[index][:3],\n",
        "        'suffix-1': sentence[index][-1],\n",
        "        'suffix-2': sentence[index][-2:],\n",
        "        'suffix-3': sentence[index][-3:],\n",
        "        'prev_word': '' if index == 0 else sentence[index - 1],\n",
        "        'next_word': '' if index == len(sentence) - 1 else sentence[index + 1],\n",
        "        'is_all_lower': sentence[index].islower(),\n",
        "        'is_first_cap': sentence[index][0].upper()\n",
        "    }"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "collapsed": true,
        "id": "CLfWfMl-vvbr",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def untag(tagged_sentence):\n",
        "    return [w for w, t in tagged_sentence]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "collapsed": true,
        "id": "Ps6e0h38vvbu",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Split the dataset for training and testing\n",
        "cutoff = int(.75 * len(sentences))\n",
        "training_sentences = sentences[:cutoff]\n",
        "test_sentences = sentences[cutoff:]\n",
        "\n",
        "\n",
        "def transform_to_dataset(tagged_sentences):\n",
        "    X, y = [], []\n",
        " \n",
        "    for tagged in tagged_sentences:\n",
        "        for index in range(len(tagged)):\n",
        "            X.append(features(untag(tagged), index))\n",
        "            y.append(tagged[index][1])\n",
        " \n",
        "    return X, y\n",
        " \n",
        "X, y = transform_to_dataset(training_sentences)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "2Wi1Ux1Ivvbw",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## 3.3. В качестве классификатора используем DecisionTreeClassifier"
      ]
    },
    {
      "metadata": {
        "collapsed": true,
        "id": "_-FD8jwTvvbx",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.feature_extraction import DictVectorizer\n",
        "from sklearn.pipeline import Pipeline\n",
        "\n",
        "\n",
        "clf = Pipeline([\n",
        "    ('vectorizer', DictVectorizer(sparse=False)),\n",
        "    ('classifier', DecisionTreeClassifier(criterion='entropy'))\n",
        "])\n",
        "\n",
        "\n",
        "# Используем не все примеры (может не хватить оперативной памяти или долго обучаться)\n",
        "bound = 10000\n",
        "clf.fit(X[:bound], y[:bound])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "collapsed": true,
        "id": "8fJNX5Xqvvbz",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "X_test, y_test = transform_to_dataset(test_sentences)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "collapsed": true,
        "id": "2liVvQ5Kvvb1",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "clf.score(X_test, y_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "-r3DUfLdvvb3",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## 3.4. Используйте RandomForestClassifier"
      ]
    },
    {
      "metadata": {
        "collapsed": true,
        "id": "2baRM92ovvb4",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "\n",
        "clf = <your code here>\n",
        "\n",
        "# Используем не все примеры (может не хватить оперативной памяти или долго обучаться)\n",
        "bound = 10000\n",
        "clf.fit(X[:bound], y[:bound])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "collapsed": true,
        "id": "pxK1LEgTvvb7",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "clf.score(X_test, y_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "N_TnTp4jvvb-",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## 3.5. Используем с помощью CRF"
      ]
    },
    {
      "metadata": {
        "collapsed": true,
        "id": "R7HWF6uXvvb_",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "len(sentences)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "collapsed": true,
        "id": "OosLWcBdvvcA",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "train, test = sentences[:-cutoff], sentences[-cutoff:]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "collapsed": true,
        "id": "e8lm3OMnvvcH",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from nltk.tag import CRFTagger"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "collapsed": true,
        "id": "ZLJv4OojvvcJ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "ct = CRFTagger()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "collapsed": true,
        "id": "04OwcWLivvcN",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "ct.train(train ,'model.crf.tagger')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "collapsed": true,
        "id": "qujdO27HvvcP",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "ct.evaluate(test)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}